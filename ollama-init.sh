#!/bin/bash

# ============================================
# LEARNING: Startup Script
# ============================================
# This script runs when the Ollama container starts
# It downloads the Mistral model if it's not already present
# 
# Why a script? Because we need to:
# 1. Wait for Ollama service to be ready
# 2. Download the model (only once)
# 3. Keep the container running

echo "ğŸš€ Starting Ollama service..."

# Start Ollama in the background
ollama serve &

# Wait for Ollama to be ready
echo "â³ Waiting for Ollama to be ready..."
sleep 5

# Check if Mistral model is already downloaded
if ! ollama list | grep -q "mistral"; then
    echo "ğŸ“¥ Downloading Mistral model (this may take a few minutes)..."
    ollama pull mistral
    echo "âœ… Mistral model downloaded successfully!"
else
    echo "âœ… Mistral model already present"
fi

# Check if embedding model is already downloaded
if ! ollama list | grep -q "nomic-embed-text"; then
    echo "ğŸ“¥ Downloading nomic-embed-text model..."
    ollama pull nomic-embed-text
    echo "âœ… Embedding model downloaded successfully!"
else
    echo "âœ… Embedding model already present"
fi

# Keep the container running
echo "ğŸ‰ Ollama is ready!"
wait
